{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbPApI7pbK7W"
      },
      "source": [
        "!pip install git+https://github.com/lesc-ufv/cad4u &> /dev/null\n",
        "!git clone https://github.com/lesc-ufv/cad4u &> /dev/null\n",
        "%load_ext plugin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp2gpshU9U1m"
      },
      "source": [
        "\n",
        "Considere que desejamos gerar um array B através de um array A de mesmo tamanho, de modo que, cada elemento `B[i]` é dado pela soma do elemento `A[i]` mais os `r` elementos anteriores à posição `i` em A mais os `r` elementos posteriores, ou seja:\n",
        "```\n",
        "for(j=i-r; j<=i+r; j++)\n",
        "    B[i]+=A[j]\n",
        "```\n",
        "O código dado a seguir já faz o cálculo do array B (armazenado em `b_cpu`) de forma sequencial. Escreva um kernel CUDA, bem como todo o restante do código necessário para executá-lo, de modo a permitir o cálculo de B de forma paralela.\n",
        "\n",
        "As posições inválidas no início e final do array A devem ser simplesmente descartadas durante a soma, ou seja, para cálculo de `B[10]` com `r=32`, o resultado será a soma dos elementos de `A[0]` até `A[42]`.\n",
        "\n",
        "Se atente para os seguinte requisitos:\n",
        "* O cálculo dos elementos de B deve ser realizado de forma paralela;\n",
        "* A memória compartilhada da GPU deve ser utilizada de forma a deixar a operação mais eficiente;\n",
        "* O código deve tratar corretamente arrays grandes divididos em mais de um bloco.\n",
        "\n",
        "Dicas:\n",
        "* O código abaixo utiliza a constante `RANGE` para definir o valor de `r` e a constante `BLOCKSIZE` para definir o tamanho de cada bloco do grid;\n",
        "* Por simplicidade, você pode considerar que o tamanho do array A será sempre múltiplo de `BLOCKSIZE`;\n",
        "* Considere também que o tamanho de `r` será no mínimo igual a 0 e no máximo igual à metade de `BLOCKSIZE`, ou seja, o tamanho do array alocado na memória compartilhada será no máximo igual a `2*BLOCKSIZE`, e no mínimo igual ` BLOCKSIZE`.\n",
        "* A estratégia utilizada pela versão sequencial de testar cada posição (para descobrir se é válida) não é ótima. Muitas comparações desnecessárias são realizadas ao calcular as posições intermediárias. Na versão paralela, é melhor preecher as posições inválidas com o valor 0 (zero) ao copiar os dados para a memória compartilhada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7rUJaOP0hfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c7b7eb2-084e-4d2a-aef5-9c800b8dae91"
      },
      "source": [
        "%%gpu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <chrono>  // Para medir o tempo na CPU\n",
        "\n",
        "#define BLOCKSIZE 1024  // Threads por bloco\n",
        "#define RANGE 256       // Deslocamento utilizado para cálculo de B\n",
        "\n",
        "// Função para inicializar o array A\n",
        "void initArray(int *a, int n) {\n",
        "    for (int i = 0; i < n; ++i)\n",
        "        a[i] = i;\n",
        "}\n",
        "\n",
        "// Função para imprimir o array\n",
        "void printArray(int *a, int n) {\n",
        "    int maxPrint = 20;  // Limita o número de elementos impressos\n",
        "    for (int i = 0; i < std::min(n, maxPrint); ++i)\n",
        "        printf(\"%5d \", a[i]);\n",
        "    if (n > maxPrint) printf(\"... (array truncado)\");\n",
        "    printf(\"\\n\");\n",
        "}\n",
        "\n",
        "// Função para comparar dois arrays\n",
        "bool checkArray(int *a, int *b, int n) {\n",
        "    for (int i = 0; i < n; ++i)\n",
        "        if (a[i] != b[i])\n",
        "            return false;\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// Execução do cálculo na CPU\n",
        "void execHost(int *A, int n, int *B) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        int soma = 0;\n",
        "        for (int j = i - RANGE; j <= i + RANGE; j++)\n",
        "            if (j >= 0 && j < n)\n",
        "                soma += A[j];\n",
        "        B[i] = soma;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Execução do cálculo na GPU usando memória compartilhada\n",
        "__global__\n",
        "void execDevice(int* A, int *B, int n) {\n",
        "    // Tamanho do array compartilhado (bloco + margens para o RANGE)\n",
        "    int shared_SIZE = BLOCKSIZE + 2 * RANGE;\n",
        "    __shared__ int sharedVec[BLOCKSIZE + 2 * RANGE];\n",
        "\n",
        "    int globalIdx = blockIdx.x * blockDim.x + threadIdx.x; // Índice global\n",
        "    int localIdx = threadIdx.x; // Índice local no bloco\n",
        "\n",
        "    // Índices inicial e final para carregar margens no array compartilhado\n",
        "    int startIdx = blockIdx.x * blockDim.x - RANGE;\n",
        "    int endIdx = (blockIdx.x + 1) * blockDim.x + RANGE - 1;\n",
        "\n",
        "    // Carregar elementos no array compartilhado\n",
        "    if (globalIdx >= 0 && globalIdx < n) {\n",
        "        sharedVec[localIdx + RANGE] = A[globalIdx];\n",
        "    } else {\n",
        "        sharedVec[localIdx + RANGE] = 0;  // Fora do array, inicializa com 0\n",
        "    }\n",
        "\n",
        "    // Carregar margem esquerda\n",
        "    if (globalIdx - RANGE < 0) {\n",
        "        sharedVec[localIdx] = 0;\n",
        "    } else {\n",
        "        sharedVec[localIdx] = A[globalIdx - RANGE];\n",
        "    }\n",
        "\n",
        "    // Carregar margem direita\n",
        "    if (globalIdx + RANGE >= n) {\n",
        "        sharedVec[localIdx + RANGE + RANGE] = 0;\n",
        "    } else {\n",
        "        sharedVec[localIdx + RANGE + RANGE] = A[globalIdx + RANGE];\n",
        "    }\n",
        "\n",
        "    __syncthreads();  // Sincronização das threads do bloco\n",
        "\n",
        "    // Cálculo da soma\n",
        "    if (globalIdx >= 0 && globalIdx < n) {\n",
        "        int soma = 0;\n",
        "        for (int i = 0; i < (RANGE * 2) + 1; i++) {\n",
        "            soma += sharedVec[localIdx + i];\n",
        "        }\n",
        "        B[globalIdx] = soma;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 1 << 20;              // Tamanho dos arrays A e B\n",
        "    int *a = new int[N];\n",
        "    int *b_cpu = new int[N];      // Array B calculado na CPU\n",
        "    int *b_gpu = new int[N];      // Array B calculado na GPU\n",
        "\n",
        "    // Inicializar array A\n",
        "    initArray(a, N);\n",
        "    printf(\"    A: \");\n",
        "    printArray(a, N);\n",
        "\n",
        "    // Alocação de memória na GPU\n",
        "    int *d_a, *d_b;\n",
        "    cudaError_t err;\n",
        "    int size = N * sizeof(int);\n",
        "\n",
        "    err = cudaMalloc((void**)&d_a, size);\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"Erro na alocação de memória para A: %s\\n\", cudaGetErrorString(err));\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    err = cudaMalloc((void**)&d_b, size);\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"Erro na alocação de memória para B: %s\\n\", cudaGetErrorString(err));\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    // Copiar array A para a GPU\n",
        "    err = cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"Erro na cópia de memória de A para o dispositivo: %s\\n\", cudaGetErrorString(err));\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    // Medir tempo de execução na GPU\n",
        "    int sharedMemSize = (BLOCKSIZE + 2 * RANGE) * sizeof(int);\n",
        "    int numBlocks = (N + BLOCKSIZE - 1) / BLOCKSIZE;\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    execDevice<<<numBlocks, BLOCKSIZE, sharedMemSize>>>(d_a, d_b, N);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    cudaEventSynchronize(stop);\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    // Copiar resultados da GPU para a CPU\n",
        "    err = cudaMemcpy(b_gpu, d_b, size, cudaMemcpyDeviceToHost);\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"Erro na cópia de memória de B para a CPU: %s\\n\", cudaGetErrorString(err));\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    printf(\"B-GPU: \");\n",
        "    printArray(b_gpu, N);\n",
        "\n",
        "    // Medir tempo de execução na CPU\n",
        "    auto startHost = std::chrono::high_resolution_clock::now();\n",
        "    execHost(a, N, b_cpu);\n",
        "    auto endHost = std::chrono::high_resolution_clock::now();\n",
        "    auto durationHost = std::chrono::duration_cast<std::chrono::milliseconds>(endHost - startHost).count();\n",
        "\n",
        "\n",
        "    printf(\"B-CPU: \");\n",
        "    printArray(b_cpu, N);\n",
        "\n",
        "    // Verificar se os resultados são iguais\n",
        "    if (checkArray(b_gpu, b_cpu, N))\n",
        "        printf(\"Resultados iguais\\n\");\n",
        "    else\n",
        "        printf(\"Resultados diferentes\\n\");\n",
        "\n",
        "\n",
        "\n",
        "    printf(\"Tempo de execução na GPU: %.3f ms\\n\", milliseconds);\n",
        "     printf(\"Tempo de execução na CPU: %lld ms\\n\", durationHost);\n",
        "    // Liberar memória\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    delete[] a;\n",
        "    delete[] b_cpu;\n",
        "    delete[] b_gpu;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    A:     0     1     2     3     4     5     6     7     8     9    10    11    12    13    14    15    16    17    18    19 ... (array truncado)\n",
            "B-GPU: 32896 33153 33411 33670 33930 34191 34453 34716 34980 35245 35511 35778 36046 36315 36585 36856 37128 37401 37675 37950 ... (array truncado)\n",
            "B-CPU: 32896 33153 33411 33670 33930 34191 34453 34716 34980 35245 35511 35778 36046 36315 36585 36856 37128 37401 37675 37950 ... (array truncado)\n",
            "Resultados iguais\n",
            "Tempo de execução na GPU: 1.640 ms\n",
            "Tempo de execução na CPU: 1538 ms\n",
            "\n"
          ]
        }
      ]
    }
  ]
}